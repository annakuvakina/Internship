{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "#import scipy.io\n",
    "import numpy as np\n",
    "#mnist = scipy.io.loadmat(\"C:\\\\Users\\\\User\\\\Desktop\\\\Internship\\\\mnist-original.mat\")\n",
    "#print(mnist[\"data\"].shape)\n",
    "#print(mnist[\"target\"].shape)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "#iris[\"data\"] = iris[\"data\"].T\n",
    "print(iris[\"data\"].shape)\n",
    "print(iris[\"target\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train + validation training set (60000, 784)\n",
    "# X_test test set (10000, 784)\n",
    "# y_train_val labels of the train set (60000,) (vector)\n",
    "# y_test labels of the test set \n",
    "#First, divide the data set into (train+validation) and test. Then devide (train+val) into train and val \n",
    "#train 50000, test 100000, val 100000\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    iris[\"data\"], iris[\"target\"], test_size=20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=20, random_state=42)\n",
    "\n",
    "#print(X_train_val)\n",
    "#print(X_test)\n",
    "#print(\"Labels\")\n",
    "#print(y_train_val)\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33333333]\n",
      " [ 0.33333333]\n",
      " [ 0.33333333]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#apriori probabilities for each number \n",
    "apriori_array = np.zeros([4,1])\n",
    "for i in range(0,4):\n",
    "    apriori_array[i] = np.prod(iris[\"target\"][iris[\"target\"]==i].shape)\n",
    "    \n",
    "apriori_array = apriori_array / np.prod(iris[\"target\"].shape)\n",
    "print(apriori_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_forest_clf = RandomForestClassifier(random_state=42)\n",
    "extra_trees_clf = ExtraTreesClassifier(random_state=42)\n",
    "#svm_clf = LinearSVC(random_state=42,)\n",
    "mlp_clf = MLPClassifier(random_state=42, max_iter=800)\n",
    "#gaussianNB_clf = GaussianNB(apriori_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 4)\n",
      "(110,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "Training the ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "Training the MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=800, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "estimators = [random_forest_clf, extra_trees_clf, mlp_clf]\n",
    "for estimator in estimators:\n",
    "    print(\"Training the\", estimator)\n",
    "    estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of the predictions:\n",
      "0.85\n",
      "0.9\n",
      "0.95\n",
      "Weights:\n",
      "[4914.7688402991344, 8103.0839275753842, 13359.726829661873]\n"
     ]
    }
   ],
   "source": [
    "##score() method measures the quality of the predictions given a test set\n",
    "# где модели делают предикшены? когда вызывается .score()\n",
    "value = []\n",
    "print(\"Quality of the predictions:\")\n",
    "[estimator.score(X_val, y_val) for estimator in estimators]\n",
    "\n",
    "for estimator in estimators:\n",
    "    print(estimator.score(X_val, y_val))\n",
    "    \n",
    "print(\"Weights:\")\n",
    "for estimator in estimators:\n",
    "    exp_weight=np.exp(10*estimator.score(X_val, y_val))\n",
    "    value.append(np.exp(10*estimator.score(X_val, y_val)))\n",
    "print(value)\n",
    "sum_value=sum(value)\n",
    "#print(\"Normalized weights:\")\n",
    "#for estimator in estimators:\n",
    "    #exp_weight=np.exp(10*estimator.score(X_val, y_val))/sum_value\n",
    "    #print(exp_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#print missclassified elements     \n",
    "\n",
    "for estimator in estimators:\n",
    "    print(y_val[estimator.predict(X_val) != y_val])\n",
    "    print('____________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking of first level learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18632372  0.30719589  0.50648039]\n"
     ]
    }
   ],
   "source": [
    "normalized_weights = (value/sum_value)\n",
    "print(normalized_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3)\n",
      "(20, 3)\n",
      "(20, 3)\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=1.0, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.8333333333333334, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.8333333333333334, total=   0.0s\n",
      "Mean score for training of the 2nd level learner = 0.888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#predict_proba(X_val) returns probability estimates for the test vector X, e.g. predcit elements 0-9 and provide its probability\n",
    "#predict computes argmax of  predic_prob\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "i = 0\n",
    "for estimator in estimators:\n",
    "    prob_for_est = estimator.predict_proba(X_val) \n",
    "    prob_for_est *= normalized_weights[i]\n",
    "    print(prob_for_est.shape)\n",
    "    if i == 0:\n",
    "        X_train2 = prob_for_est\n",
    "    else:\n",
    "        X_train2 = np.hstack((X_train2, prob_for_est))\n",
    "    i+=1\n",
    "    \n",
    "#print(X_train2.shape)\n",
    "    \n",
    "y_train2 = y_val\n",
    "    \n",
    "log_clf.fit(X_train2, y_train2)\n",
    "\n",
    "score = cross_val_score(log_clf, X_train2, y_train2, cv=3, verbose=3)\n",
    "mean_score = score.mean()\n",
    "print(\"Mean score for training of the 2nd level learner = %f\" % mean_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=1.0, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.8571428571428571, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=1.0, total=   0.0s\n",
      "Mean score for test set of the 2nd level learner = 0.952381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for estimator in estimators:\n",
    "    prob_for_est = estimator.predict_proba(X_test) \n",
    "    prob_for_est *= normalized_weights[i]\n",
    "    #print(prob_for_est.shape)\n",
    "    if i == 0:\n",
    "        X_test2 = prob_for_est\n",
    "    else:\n",
    "        X_test2 = np.hstack((X_test2, prob_for_est))\n",
    "    i+=1\n",
    "    \n",
    "#print(X_train2.shape)\n",
    "    \n",
    "y_test2 = y_test\n",
    "    \n",
    "#log_clf.predict(X_test2, y_test2)\n",
    "\n",
    "score = cross_val_score(log_clf, X_test2, y_test2, cv=3, verbose=3)\n",
    "mean_score = score.mean()\n",
    "print(\"Mean score for test set of the 2nd level learner = %f\" % mean_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=1.0, total=   2.8s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................................... , score=1.0, total=   2.7s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................................... , score=1.0, total=   2.8s\n",
      "Mean score for test set of the 2nd level learner = 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    8.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=4,\n",
    "     bootstrap=True, n_jobs=-1, random_state=42) #max_samples=100,\n",
    "bag_clf.fit(X_train, y_train)\n",
    "#y_pred = bag_clf.predict(X_test)\n",
    "#score = cross_val_score(bag_clf, X_train2, y_train2, cv=3, verbose=3)\n",
    "#mean_score = score.mean()\n",
    "#print(\"Mean score for training of the 2nd level learner = %f\" % mean_score)\n",
    "score = cross_val_score(bag_clf, X_test, y_test, cv=3, verbose=3)\n",
    "mean_score = score.mean()\n",
    "print(\"Mean score for test set of the 2nd level learner = %f\" % mean_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=1.0, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=1.0, total=   0.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................................... , score=1.0, total=   0.1s\n",
      "Mean score for test set of the 2nd level learner = 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "score = cross_val_score(ada_clf, X_test, y_test, cv=3, verbose=3)\n",
    "mean_score = score.mean()\n",
    "print(\"Mean score for test set of the 2nd level learner = %f\" % mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "named_estimators = [\n",
    "    (\"random_forest_clf\", random_forest_clf),\n",
    "    (\"extra_trees_clf\", extra_trees_clf),\n",
    "    #(\"gaussianNB_clf\", gaussianNB_clf),\n",
    "    (\"mlp_clf\", mlp_clf),\n",
    "]\n",
    "voting_clf = VotingClassifier(named_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "   ...       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier SOFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voting_clf.voting = \"soft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
