{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 70000)\n",
      "(1, 70000)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "mnist = scipy.io.loadmat(\"C:\\\\Users\\\\User\\\\Desktop\\\\Internship\\\\mnist-original.mat\")\n",
    "print(mnist[\"data\"].shape)\n",
    "print(mnist[\"target\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(np.ravel(mnist[\"target\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train + validation training set (60000, 784)\n",
    "# X_test test set (10000, 784)\n",
    "# y_train_val labels of the train set (60000,) (vector)\n",
    "# y_test labels of the test set \n",
    "#First, divide the data set into (train+validation) and test. Then devide (train+val) into train and val \n",
    "#train 50000, test 100000, val 100000\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    mnist[\"data\"].T, np.ravel(mnist[\"target\"]), test_size=10000, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=10000, random_state=42)\n",
    "\n",
    "#print(X_train_val)\n",
    "#print(X_test)\n",
    "#print(\"Labels\")\n",
    "#print(y_train_val)\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apriori probabilities for each number \n",
    "apriori_array = np.zeros([10,1])\n",
    "for i in range(0,10):\n",
    "    apriori_array[i] = np.prod(mnist[\"target\"][mnist[\"target\"]==i].shape)\n",
    "    \n",
    "apriori_array = apriori_array / np.prod(mnist[\"target\"].shape)\n",
    "#print(apriori_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_forest_clf = RandomForestClassifier(random_state=42)\n",
    "extra_trees_clf = ExtraTreesClassifier(random_state=42)\n",
    "svm_clf = svm.SVC(random_state=42,probability = True)\n",
    "mlp_clf = MLPClassifier(random_state=42)\n",
    "gaussianNB_clf = GaussianNB(apriori_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "Training the ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "Training the SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=42, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "estimators = [random_forest_clf, extra_trees_clf,svm_clf, mlp_clf]\n",
    "for estimator in estimators:\n",
    "    print(\"Training the\", estimator)\n",
    "    estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##score() method measures the quality of the predictions given a test set\n",
    "# где модели делают предикшены? когда вызывается .score()\n",
    "value = []\n",
    "print(\"Quality of the predictions:\")\n",
    "[estimator.score(X_val, y_val) for estimator in estimators]\n",
    "\n",
    "for estimator in estimators:\n",
    "    print(estimator.score(X_val, y_val))\n",
    "    \n",
    "print(\"Weights:\")\n",
    "for estimator in estimators:\n",
    "    exp_weight=np.exp(10*estimator.score(X_val, y_val))\n",
    "    value.append(np.exp(10*estimator.score(X_val, y_val)))\n",
    "print(value)\n",
    "sum_value=sum(value)\n",
    "#print(\"Normalized weights:\")\n",
    "#for estimator in estimators:\n",
    "    #exp_weight=np.exp(10*estimator.score(X_val, y_val))/sum_value\n",
    "    #print(exp_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#print missclassified elements     \n",
    "\n",
    "for estimator in estimators:\n",
    "    print(y_val[estimator.predict(X_val) != y_val])\n",
    "    print('____________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking of first level learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_weights = (value/sum_value)\n",
    "print(normalized_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#predict_proba(X_val) returns probability estimates for the test vector X, e.g. predcit elements 0-9 and provide its probability\n",
    "#predict computes argmax of  predic_prob\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "i = 0\n",
    "for estimator in estimators:\n",
    "    prob_for_est = estimator.predict_proba(X_val) \n",
    "    prob_for_est *= normalized_weights[i]\n",
    "    print(prob_for_est.shape)\n",
    "    if i == 0:\n",
    "        X_train2 = prob_for_est\n",
    "    else:\n",
    "        X_train2 = np.hstack((X_train2, prob_for_est))\n",
    "    i+=1\n",
    "    \n",
    "#print(X_train2.shape)\n",
    "    \n",
    "y_train2 = y_val\n",
    "    \n",
    "log_clf.fit(X_train2, y_train2)\n",
    "\n",
    "score = cross_val_score(log_clf, X_train2, y_train2, cv=3, verbose=3)\n",
    "mean_score = score.mean()\n",
    "print(\"Blender mean score on the training dataset = %f\" % mean_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for estimator in estimators:\n",
    "    prob_for_est = estimator.predict_proba(X_test) \n",
    "    prob_for_est *= normalized_weights[i]\n",
    "    #print(prob_for_est.shape)\n",
    "    if i == 0:\n",
    "        X_test2 = prob_for_est\n",
    "    else:\n",
    "        X_test2 = np.hstack((X_test2, prob_for_est))\n",
    "    i+=1\n",
    "    \n",
    "#print(X_train2.shape)\n",
    "    \n",
    "y_test2 = y_test\n",
    "    \n",
    "#log_clf.predict(X_test2, y_test2)\n",
    "\n",
    "score = cross_val_score(log_clf, X_test2, y_test2, cv=3, verbose=3)\n",
    "mean_score = score.mean()\n",
    "print(\"Blender mean score for a testing dataset set = %f\" % mean_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=4,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "#y_pred = bag_clf.predict(X_test)\n",
    "#score = cross_val_score(bag_clf, X_train2, y_train2, cv=3, verbose=3)\n",
    "#mean_score = score.mean()\n",
    "#print(\"Mean score for training of the 2nd level learner = %f\" % mean_score)\n",
    "score = cross_val_score(bag_clf, X_test, y_test, cv=3, verbose=3)\n",
    "mean_score = score.mean()\n",
    "print(\"Mean score for test set of the 2nd level learner = %f\" % mean_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=4,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "score = cross_val_score(ada_clf, X_test, y_test, cv=3, verbose=3)\n",
    "mean_score = score.mean()\n",
    "print(\"Mean score for test set of the 2nd level learner = %f\" % mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "named_estimators = [\n",
    "    (\"random_forest_clf\", random_forest_clf),\n",
    "    (\"extra_trees_clf\", extra_trees_clf),\n",
    "    (\"gaussianNB_clf\", gaussianNB_clf),\n",
    "    (\"mlp_clf\", mlp_clf),\n",
    "]\n",
    "voting_clf = VotingClassifier(named_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier SOFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voting_clf.voting = \"soft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
